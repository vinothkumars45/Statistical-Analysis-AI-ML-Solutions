{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a67ca772-3984-4e99-ad43-8a595e45db36",
   "metadata": {},
   "source": [
    "# Library imports and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1e61ee3-c932-4d19-ba80-d1919d02c359",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.stats import kstest # to check if the samples are normally distributed\n",
    "from scipy.stats import levene #Levene's test\n",
    "from scipy.stats import ttest_ind # 2 sample t-test \n",
    "from scipy.stats import t # confidence Interval of the difference\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "from io import StringIO\n",
    "\n",
    "os.chdir(\"C:/Users/vinotsek/Desktop/Statistical Analysis\")\n",
    "def convert_to_million_currency(series):\n",
    "    return series.apply(lambda x: \"${:,.2f}M\".format(x / 1_000000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4310b2-b87c-4355-883d-e7786d141694",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Read, clean & manipulate the service offer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5dd1c61e-b74f-4623-99df-6ad8b06749a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vinotsek\\jupyterenv\\Lib\\site-packages\\openpyxl\\styles\\stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "C:\\Users\\vinotsek\\jupyterenv\\Lib\\site-packages\\openpyxl\\styles\\stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "C:\\Users\\vinotsek\\AppData\\Local\\Temp\\ipykernel_27088\\3987222081.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  CX[\"ERP Deal ID\"].fillna(\"Unknown\",inplace=True)\n",
      "C:\\Users\\vinotsek\\AppData\\Local\\Temp\\ipykernel_27088\\3987222081.py:23: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  CX[\"EC_Deal\"].fillna(\"N\",inplace=True)\n",
      "C:\\Users\\vinotsek\\AppData\\Local\\Temp\\ipykernel_27088\\3987222081.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  CX[\"ST_Deal\"].fillna(\"N\",inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# CX denotes Cisco services business\n",
    "AS=pd.read_excel(\"raw_data/AS.xlsx\")\n",
    "TS=pd.read_excel(\"raw_data/TS.xlsx\")\n",
    "AS.drop(columns=['AS Architecture','AS Offer Type','AS Technology'],axis=1,inplace=True)\n",
    "CX = pd.concat([AS,TS],axis=0)\n",
    "CX = CX[CX[\"Fiscal Year\"].isin([2024,2023])]\n",
    "CX[\"ERP Deal ID\"].fillna(\"Unknown\",inplace=True)\n",
    "CX[\"Inter\"] = [row.split('-')[1] if len(row.split('-')) > 1 else None for row in CX[\"Sub SCMS\"]]\n",
    "map = CX.groupby([\"End Customer Global Ultimate Name\",\"Inter\"])[\"CA Service Bookings Net\"].sum().sort_values(ascending = False).reset_index().drop_duplicates(subset=[\"End Customer Global Ultimate Name\"])\n",
    "map.rename(columns={\"Inter\":\"Tier\"},inplace=True)\n",
    "CX[\"Tier\"] = CX[\"End Customer Global Ultimate Name\"].map(dict(zip(map[\"End Customer Global Ultimate Name\"],map[\"Tier\"])))\n",
    "CX.drop(\"Inter\",axis=1,inplace=True)\n",
    "#CX=CX[CX[\"Tier\"].isin([\"PREMIER\",\"KEY\",\"MAJOR\"])]\n",
    "#convert_to_million_currency(CX.groupby(\"CX Product Portfolio\")[\"CA Service Bookings Net\"].sum())\n",
    "\n",
    "#New column to map EC deals\n",
    "EC_Deals = CX[CX[\"CX Product Category\"] == 'Expert Care Svcs'].groupby(\"ERP Deal ID\")[\"CA Service Bookings Net\"].sum().sort_values(ascending=False).reset_index()\n",
    "EC_Deals = EC_Deals[(EC_Deals[\"ERP Deal ID\"]!=\"Unknown\")&(EC_Deals[\"ERP Deal ID\"]!=\"UNKNOWN\")]\n",
    "EC_Deals = EC_Deals[EC_Deals[\"CA Service Bookings Net\"]>=50000]\n",
    "EC_Deals[\"EC_Deal\"]=\"Y\"\n",
    "EC_Deals.drop(columns=\"CA Service Bookings Net\",inplace=True)\n",
    "EC_dict = dict(zip(EC_Deals[\"ERP Deal ID\"],EC_Deals[\"EC_Deal\"]))\n",
    "CX[\"EC_Deal\"] = CX[\"ERP Deal ID\"].map(EC_dict)\n",
    "CX[\"EC_Deal\"].fillna(\"N\",inplace=True)\n",
    "\n",
    "#New column to map ST deals\n",
    "ST_Deals = CX[CX[\"CX Product Portfolio\"]==\"Success Tracks\"].groupby(\"ERP Deal ID\")[\"CA Service Bookings Net\"].sum().sort_values(ascending=False).reset_index()\n",
    "ST_Deals = ST_Deals[(ST_Deals[\"ERP Deal ID\"]!=\"Unknown\")&(ST_Deals[\"ERP Deal ID\"]!=\"UNKNOWN\")]\n",
    "ST_Deals = ST_Deals[ST_Deals[\"CA Service Bookings Net\"]>=10000]\n",
    "ST_Deals[\"ST_Deal\"]=\"Y\"\n",
    "ST_Deals.drop(columns=\"CA Service Bookings Net\",inplace=True)\n",
    "ST_dict = dict(zip(ST_Deals[\"ERP Deal ID\"],ST_Deals[\"ST_Deal\"]))\n",
    "CX[\"ST_Deal\"] = CX[\"ERP Deal ID\"].map(ST_dict)\n",
    "CX[\"ST_Deal\"].fillna(\"N\",inplace=True)\n",
    "\n",
    "#ST Discount dataset\n",
    "CX1= CX[CX[\"CX Product Portfolio\"]==\"Success Tracks\"]\n",
    "CX1= CX1[CX1[\"ST_Deal\"]==\"Y\"]\n",
    "CX1=CX1.groupby([\"ERP Deal ID\",\"EC_Deal\"]).agg(List_Price = (\"CA Service Bookings Standard List\",\"sum\"),Net_Price=(\"CA Service Bookings Net\",\"sum\")).reset_index()\n",
    "CX1[\"Discount\"]=(CX1[\"List_Price\"]-CX1[\"Net_Price\"])/CX1[\"List_Price\"]\n",
    "#CX1=CX1[(CX1[\"Discount\"]>=0) & (CX1[\"Discount\"]<=1)] #removing outliers\n",
    "\n",
    "#EC Discount dataset\n",
    "CX2= CX[CX[\"CX Product Category\"] == 'Expert Care Svcs']\n",
    "CX2= CX2[CX2[\"EC_Deal\"]==\"Y\"]\n",
    "CX2=CX2.groupby([\"ERP Deal ID\",\"ST_Deal\"]).agg(List_Price = (\"CA Service Bookings Standard List\",\"sum\"),Net_Price=(\"CA Service Bookings Net\",\"sum\")).reset_index()\n",
    "CX2[\"Discount\"]=(CX2[\"List_Price\"]-CX2[\"Net_Price\"])/CX2[\"List_Price\"]\n",
    "#CX2=CX2[(CX2[\"Discount\"]>=0) & (CX2[\"Discount\"]<=1)] #removing outliers\n",
    "\n",
    "# rewriting the manipulated intermediate dataset back to the folder\n",
    "with pd.ExcelWriter(\"EC insertion to ST_Discount Analysis_output.xlsx\") as writer:\n",
    "    CX.to_excel(writer,sheet_name=\"raw_data\",index=False)\n",
    "    CX1.to_excel(writer,sheet_name=\"ST\",index=False)\n",
    "    CX2.to_excel(writer,sheet_name=\"EC\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2715d0d3-5dc9-4649-bcf3-c531b7397136",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Statistical test to identify if the distribution is normal and the variance of the sample are equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cd63fd07-6a24-4d3f-8a95-95c2b4b53ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kolmogorov-Smirnov Statistic: 0.6114219194349028\n",
      "p-value: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Perform Kolmogorov-Smirnov test on CX1 & CX2\n",
    "ks_statistic, p_value = kstest(CX2[\"Discount\"], 'norm')\n",
    "\n",
    "# Print results\n",
    "print(\"Kolmogorov-Smirnov Statistic:\", ks_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "#The result shows the distribution is not normal as the null hypothesis is rejected. \n",
    "#But still we can use parametric test as we have sufficient sample in both the category\n",
    "\n",
    "\n",
    "# Perform levene test to check if the variance of the sample are equal\n",
    "# Assuming sample1 and sample2 are your two samples\n",
    "statistic, p_value = levene(CX1[CX1[\"EC_Deal\"]==\"Y\"][\"Discount\"], CX1[CX1[\"EC_Deal\"]==\"N\"][\"Discount\"])\n",
    "print(\"Levene's Test Statistic:\", statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "#reject the null hypothesis and conclude that the variance of the sample are not equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "56d05649-6327-4fe6-a8d8-cc16db03a885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.1998741318293975 3.701877189721089e-09\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'sample1' and 'sample2' are your datasets\n",
    "t_statistic, p_value = ttest_ind(CX1[CX1[\"EC_Deal\"]==\"Y\"][\"Discount\"], CX1[CX1[\"EC_Deal\"]==\"N\"][\"Discount\"], equal_var=False)  # equal_var=False for unequal variances\n",
    "print(t_statistic,p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3100a7f-96b5-47e9-a2b5-6c7e5d4e90c8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Histograms of the discount distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f375c390-d1e6-419d-9b6d-e87bcf94ba5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram for ST with EC and ST without EC\n",
    "ST_with_EC = CX1[CX1[\"EC_Deal\"]==\"Y\"][\"Discount\"]\n",
    "ST_without_EC = CX1[CX1[\"EC_Deal\"]==\"N\"][\"Discount\"]\n",
    "\n",
    "# Perform two-sample t-test\n",
    "t_statistic, p_value = ttest_ind(ST_with_EC, ST_without_EC, equal_var=False)\n",
    "\n",
    "# Create overlaid histograms to visualize the distribution of the two groups\n",
    "sns.histplot(ST_with_EC, color='navy', alpha=0.7, label='ST_with_EC', kde=True)\n",
    "sns.histplot(ST_without_EC, color='lightsteelblue', alpha=0.3, label='ST_without_EC', kde=True)\n",
    "\n",
    "# Plot mean lines and annotate mean values\n",
    "mean1 = np.mean(ST_with_EC)\n",
    "mean2 = np.mean(ST_without_EC)\n",
    "plt.axvline(mean1, color='navy', linestyle='dashed', linewidth=1, label=f'Average_discount ST_with_EC: {mean1:.2f}')\n",
    "plt.axvline(mean2, color='lightsteelblue', linestyle='dashed', linewidth=1, label=f'Average_discount ST_without_EC: {mean2:.2f}')\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Discount')\n",
    "plt.ylabel('Deal Count')\n",
    "#plt.title('Distribution of Two Groups')\n",
    "\n",
    "# Save the plot as an image file\n",
    "plt.savefig('histogram_with_means(1).png')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"T-statistic:\", t_statistic)\n",
    "print(\"P-value:\", p_value)\n",
    "print(\"mean1:\",mean1)\n",
    "print(\"mean2:\",mean2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9545371-44a0-4736-ac1d-e7cc04d76f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram for EC with ST and EC without ST \n",
    "ST_with_EC = CX1[CX1[\"EC_Deal\"]==\"Y\"][\"Discount\"]\n",
    "ST_without_EC = CX1[CX1[\"EC_Deal\"]==\"N\"][\"Discount\"]\n",
    "\n",
    "EC_with_ST = CX2[CX2[\"ST_Deal\"]==\"Y\"][\"Discount\"]\n",
    "EC_without_ST = CX2[CX2[\"ST_Deal\"]==\"N\"][\"Discount\"]\n",
    "\n",
    "# Perform two-sample t-test\n",
    "t_statistic, p_value = ttest_ind(EC_with_ST, EC_without_ST, equal_var=False)\n",
    "\n",
    "# Create overlaid histograms to visualize the distribution of the two groups\n",
    "sns.histplot(EC_with_ST, color='navy', alpha=0.7, label='EC_with_ST', kde=True)\n",
    "sns.histplot(EC_without_ST, color='lightsteelblue', alpha=0.3, label='EC_without_ST', kde=True)\n",
    "\n",
    "# Plot mean lines and annotate mean values\n",
    "mean1 = np.mean(EC_with_ST)\n",
    "mean2 = np.mean(EC_without_ST)\n",
    "plt.axvline(mean1, color='navy', linestyle='dashed', linewidth=1, label=f'Average_discount EC_with_ST: {mean1:.2f}')\n",
    "plt.axvline(mean2, color='lightsteelblue', linestyle='dashed', linewidth=1, label=f'Average_discount EC_without_ST: {mean2:.2f}')\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Discount')\n",
    "plt.ylabel('Deal Count')\n",
    "#plt.title('Distribution of Two Groups')\n",
    "\n",
    "# Save the plot as an image file\n",
    "plt.savefig('histogram_with_means(2).png')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"T-statistic:\", t_statistic)\n",
    "print(\"P-value:\", p_value)\n",
    "print(\"mean1:\",mean1)\n",
    "print(\"mean2:\",mean2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f53a394-701e-4ad8-970b-3742a665db30",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Confidence Interval of two sample t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "99c3b875-e2b8-4057-90fb-bb33d81d668e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10716587288774271 0.026562486004159735\n",
      "Confidence Interval: [0.0806, 0.1337]\n"
     ]
    }
   ],
   "source": [
    "# Creating confidence interval of two sample t-test\n",
    "import numpy as np\n",
    "from scipy.stats import t\n",
    "\n",
    "# Assuming sample1 and sample2 are your two samples\n",
    "sample1 = CX1[CX1[\"EC_Deal\"]==\"Y\"][\"Discount\"]\n",
    "sample2 = CX1[CX1[\"EC_Deal\"]==\"N\"][\"Discount\"]\n",
    "\n",
    "# Calculate the difference in means\n",
    "mean_difference = np.mean(sample1) - np.mean(sample2)\n",
    "\n",
    "# Calculate the standard errors\n",
    "se1 = np.std(sample1, ddof=1) / np.sqrt(len(sample1))\n",
    "se2 = np.std(sample2, ddof=1) / np.sqrt(len(sample2))\n",
    "\n",
    "# Calculate the degrees of freedom\n",
    "degrees_freedom = ((se1 ** 2 / len(sample1)) + (se2 ** 2 / len(sample2))) ** 2 / (((se1 ** 2 / len(sample1)) ** 2) / (len(sample1) - 1) + ((se2 ** 2 / len(sample2)) ** 2) / (len(sample2) - 1))\n",
    "\n",
    "# Calculate the t-statistic\n",
    "t_statistic = mean_difference / np.sqrt(se1 ** 2 + se2 ** 2)\n",
    "\n",
    "# Calculate the critical value\n",
    "alpha = 0.05  # 95% confidence interval\n",
    "critical_value = t.ppf(1 - alpha / 2, degrees_freedom)  # two-tailed test\n",
    "\n",
    "# Calculate the margin of error\n",
    "margin_of_error = critical_value * np.sqrt(se1 ** 2 + se2 ** 2)\n",
    "\n",
    "# Calculate the confidence interval\n",
    "ci_lower = mean_difference - margin_of_error\n",
    "ci_upper = mean_difference + margin_of_error\n",
    "\n",
    "# Print confidence interval\n",
    "print(mean_difference, margin_of_error)\n",
    "print(\"Confidence Interval: [{:.4f}, {:.4f}]\".format(ci_lower, ci_upper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "09c66fd0-9054-4100-8f4e-8682eead9535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.028480855078398926 0.018699082846744527\n",
      "Confidence Interval: [-0.0472, -0.0098]\n"
     ]
    }
   ],
   "source": [
    "# Creating confidence interval of two sample t-test\n",
    "import numpy as np\n",
    "from scipy.stats import t\n",
    "\n",
    "# Assuming sample1 and sample2 are your two samples\n",
    "sample1 = CX2[CX2[\"ST_Deal\"]==\"Y\"][\"Discount\"]\n",
    "sample2 = CX2[CX2[\"ST_Deal\"]==\"N\"][\"Discount\"]\n",
    "\n",
    "# Calculate the difference in means\n",
    "mean_difference = np.mean(sample1) - np.mean(sample2)\n",
    "\n",
    "# Calculate the standard errors\n",
    "se1 = np.std(sample1, ddof=1) / np.sqrt(len(sample1))\n",
    "se2 = np.std(sample2, ddof=1) / np.sqrt(len(sample2))\n",
    "\n",
    "# Calculate the degrees of freedom\n",
    "degrees_freedom = ((se1 ** 2 / len(sample1)) + (se2 ** 2 / len(sample2))) ** 2 / (((se1 ** 2 / len(sample1)) ** 2) / (len(sample1) - 1) + ((se2 ** 2 / len(sample2)) ** 2) / (len(sample2) - 1))\n",
    "\n",
    "# Calculate the t-statistic\n",
    "t_statistic = mean_difference / np.sqrt(se1 ** 2 + se2 ** 2)\n",
    "\n",
    "# Calculate the critical value\n",
    "alpha = 0.05  # 95% confidence interval\n",
    "critical_value = t.ppf(1 - alpha / 2, degrees_freedom)  # two-tailed test\n",
    "\n",
    "# Calculate the margin of error\n",
    "margin_of_error = critical_value * np.sqrt(se1 ** 2 + se2 ** 2)\n",
    "\n",
    "# Calculate the confidence interval\n",
    "ci_lower = mean_difference - margin_of_error\n",
    "ci_upper = mean_difference + margin_of_error\n",
    "\n",
    "# Print confidence interval\n",
    "print(mean_difference, margin_of_error)\n",
    "print(\"Confidence Interval: [{:.4f}, {:.4f}]\".format(ci_lower, ci_upper))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c80e74-07e0-4603-8c62-8b211cc64d8e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Pyramid slide excel output (Summarizes the annual order value based on size categories and offers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d117d320-8305-4e33-a715-6e3cc09a19b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vinotsek\\AppData\\Local\\Temp\\ipykernel_51408\\3319432314.py:25: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  AOV_Category[\"Category\"].fillna(\"OTHER\",inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# PKM and customer count\n",
    "\n",
    "# CX_= pd.read_excel(\"raw_data/CX AOV.xlsx\")\n",
    "# CX_ =CX_[~CX_[\"CAV End Customer BU ID\"].isin([-999])]\n",
    "# CX_[\"Inter\"] = [row.split('-')[1] if len(row.split('-')) > 1 else None for row in CX_[\"Sub SCMS\"]]\n",
    "# map = CX_.groupby([\"CAV End Customer BU ID\",\"Inter\"])[\"AOV\"].sum().sort_values(ascending = False).reset_index().drop_duplicates(subset=[\"CAV End Customer BU ID\"])\n",
    "# map.rename(columns={\"Inter\":\"Tier\"},inplace=True)\n",
    "# CX_[\"Tier\"] = CX_[\"CAV End Customer BU ID\"].map(dict(zip(map[\"CAV End Customer BU ID\"],map[\"Tier\"])))\n",
    "# CX_.drop(\"Inter\",axis=1,inplace=True)\n",
    "\n",
    "AOV_Category = CX_[[\"CAV End Customer BU ID\",\"Tier\"]].drop_duplicates()\n",
    "AOV_Category = AOV_Category.rename(columns={\"Tier\":\"Category\"})\n",
    "\n",
    "category_mapping = {\n",
    "    'PREMIER': 'PREMIER',   \n",
    "    'KEY': 'KEY',   \n",
    "    'MAJOR': 'MAJOR',  \n",
    "    'SELECT': 'SELECT',  \n",
    "    'MIDSIZE': 'OTHER',  \n",
    "    'SMALL': 'OTHER'   \n",
    "}\n",
    "\n",
    "# Apply the mapping to the 'Category' column\n",
    "AOV_Category['Category'] = AOV_Category['Category'].replace(category_mapping)\n",
    "AOV_Category[\"Category\"].fillna(\"OTHER\",inplace=True)\n",
    "\n",
    "#CX\n",
    "CX_AOV = CX_.groupby('CAV End Customer BU ID')['AOV'].agg(CX_AOV='sum').reset_index()\n",
    "Overall_CX_AOV = CX_AOV['CX_AOV'].sum()\n",
    "\n",
    "#ST\n",
    "ST_AOV = CX_[CX_[\"CX Product Category\"].isin([\"Level 1\",\"Level 2\",\"Level Unknown\"])]\n",
    "ST_AOV = ST_AOV.groupby('CAV End Customer BU ID')['AOV'].agg(ST_AOV='sum').reset_index()\n",
    "Overall_ST_AOV = ST_AOV['ST_AOV'].sum()\n",
    "\n",
    "#SSPT\n",
    "SSPT_AOV = CX_[CX_[\"CX Product Category\"]==\"Solution Support\"]\n",
    "SSPT_AOV = SSPT_AOV.groupby('CAV End Customer BU ID')['AOV'].agg(SSPT_AOV='sum').reset_index()\n",
    "Overall_SSPT_AOV = SSPT_AOV['SSPT_AOV'].sum()\n",
    "\n",
    "#EC\n",
    "EC_AOV = CX_[CX_[\"CX Product Category\"]==\"Expert Care Svcs\"]\n",
    "EC_AOV = EC_AOV.groupby('CAV End Customer BU ID')['AOV'].agg(EC_AOV='sum').reset_index()\n",
    "Overall_EC_AOV = EC_AOV['EC_AOV'].sum()\n",
    "\n",
    "table_list=[AOV_Category,CX_AOV,ST_AOV,SSPT_AOV,EC_AOV]\n",
    "\n",
    "base_df= CX_[\"CAV End Customer BU ID\"]\n",
    "\n",
    "base_df=pd.DataFrame(base_df.drop_duplicates())\n",
    "\n",
    "# Iterate through the list and left join each table to the base_df\n",
    "for table in table_list:\n",
    "    base_df = base_df.merge(table, on='CAV End Customer BU ID', how='left')\n",
    "    \n",
    "base_df = base_df.fillna(0)\n",
    "\n",
    "base_df[\"#CX\"] = np.where(base_df[\"CX_AOV\"]>10000,1,0)\n",
    "base_df[\"#ST\"] = np.where(base_df[\"ST_AOV\"]>10000,1,0)\n",
    "base_df[\"#SSPT\"] = np.where(base_df[\"SSPT_AOV\"]>10000,1,0)\n",
    "base_df[\"#EC\"] = np.where(base_df[\"EC_AOV\"]>50000,1,0)\n",
    "\n",
    "base_df.to_excel(\"Pyramid_raw1.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d8f6cbaf-a58d-410e-a99a-5aa4938c5e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AOV category & size\n",
    "\n",
    "CX_= pd.read_excel(\"raw_data/CX AOV.xlsx\")\n",
    "CX_ =CX_[~CX_[\"CAV End Customer BU ID\"].isin([-999])]\n",
    "CX_[\"Inter\"] = [row.split('-')[1] if len(row.split('-')) > 1 else None for row in CX_[\"Sub SCMS\"]]\n",
    "map = CX_.groupby([\"CAV End Customer BU ID\",\"Inter\"])[\"AOV\"].sum().sort_values(ascending = False).reset_index().drop_duplicates(subset=[\"CAV End Customer BU ID\"])\n",
    "map.rename(columns={\"Inter\":\"Tier\"},inplace=True)\n",
    "CX_[\"Tier\"] = CX_[\"CAV End Customer BU ID\"].map(dict(zip(map[\"CAV End Customer BU ID\"],map[\"Tier\"])))\n",
    "CX_.drop(\"Inter\",axis=1,inplace=True)\n",
    "CX_=CX_[CX_[\"Tier\"].isin([\"PREMIER\",\"KEY\",\"MAJOR\"])]\n",
    "\n",
    "AOV_Category = CX_.groupby([\"CAV End Customer BU ID\")[\"AOV\"].sum().reset_index()\n",
    "pd.Series(CX[\"AOV_Customer\"].unique()).describe().apply(lambda x: f\"{x:,.0f}\")\n",
    "conditions = [4r354 \n",
    "    AOV_Category['AOV'] < 10000,\n",
    "    (AOV_Category['AOV'] >= 10000) & (AOV_Category['AOV'] < 500000),\n",
    "    (AOV_Category['AOV'] >= 500000) & (AOV_Category['AOV'] < 1000000),\n",
    "    (AOV_Category['AOV'] >= 1000000) & (AOV_Category['AOV'] < 5000000),\n",
    "    (AOV_Category['AOV'] >= 5000000) & (AOV_Category['AOV'] < 10000000),\n",
    "    (AOV_Category['AOV'] >= 10000000) & (AOV_Category['AOV'] < 25000000),\n",
    "    (AOV_Category['AOV'] >= 25000000)\n",
    "]\n",
    "values = ['<$10K','$10K - $500K', '$500K - $1M', '$1M - $5M','$5M- $10M','$10M- $25M','>$25M']\n",
    "AOV_Category['category'] = np.select(conditions, values, default='')\n",
    "AOV_Category=AOV_Category.iloc[:,[0,2]]\n",
    "\n",
    "AOV_Category = CX_[[\"CAV End Customer BU ID\",\"Tier\"]]\n",
    "AOV_Category.rename(columns={\"Tier\":\"Category\"})\n",
    "\n",
    "#CX\n",
    "CX_AOV = CX_.groupby('CAV End Customer BU ID')['AOV'].agg(CX_AOV='sum').reset_index()\n",
    "Overall_CX_AOV = CX_AOV['CX_AOV'].sum()\n",
    "\n",
    "#ST\n",
    "ST_AOV = CX_[CX_[\"CX Product Category\"].isin([\"Level 1\",\"Level 2\",\"Level Unknown\"])]\n",
    "ST_AOV = ST_AOV.groupby('CAV End Customer BU ID')['AOV'].agg(ST_AOV='sum').reset_index()\n",
    "Overall_ST_AOV = ST_AOV['ST_AOV'].sum()\n",
    "\n",
    "#SSPT\n",
    "SSPT_AOV = CX_[CX_[\"CX Product Category\"]==\"Solution Support\"]\n",
    "SSPT_AOV = SSPT_AOV.groupby('CAV End Customer BU ID')['AOV'].agg(SSPT_AOV='sum').reset_index()\n",
    "Overall_SSPT_AOV = SSPT_AOV['SSPT_AOV'].sum()\n",
    "\n",
    "#EC\n",
    "EC_AOV = CX_[CX_[\"CX Product Category\"]==\"Expert Care Svcs\"]\n",
    "EC_AOV = EC_AOV.groupby('CAV End Customer BU ID')['AOV'].agg(EC_AOV='sum').reset_index()\n",
    "Overall_EC_AOV = EC_AOV['EC_AOV'].sum()\n",
    "\n",
    "table_list=[AOV_Category,CX_AOV,ST_AOV,SSPT_AOV,EC_AOV]\n",
    "\n",
    "base_df= CX_[\"CAV End Customer BU ID\"]\n",
    "\n",
    "base_df=pd.DataFrame(base_df.drop_duplicates())\n",
    "\n",
    "# Iterate through the list and left join each table to the base_df\n",
    "for table in table_list:\n",
    "    base_df = base_df.merge(table, on='CAV End Customer BU ID', how='left')\n",
    "    \n",
    "base_df = base_df.fillna(0)\n",
    "\n",
    "base_df[\"category\"]=base_df[\"category\"].replace(0,\"<$10K\")\n",
    "\n",
    "base_df[\"#CX\"] = np.where(base_df[\"CX_AOV\"]>10000,1,0)\n",
    "base_df[\"#ST\"] = np.where(base_df[\"ST_AOV\"]>10000,1,0)\n",
    "base_df[\"#SSPT\"] = np.where(base_df[\"SSPT_AOV\"]>10000,1,0)\n",
    "base_df[\"#EC\"] = np.where(base_df[\"EC_AOV\"]>10000,1,0)\n",
    "\n",
    "#base_df.to_excel(\"Pyramid_raw2.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d59dc5e-a070-4395-8ff0-1bed4b411ec2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# CSAT Data manipulation on Customer Satisfaction Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7e295351-7ab9-4423-9736-7989e16c9245",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vinotsek\\AppData\\Local\\Temp\\ipykernel_51408\\3379410815.py:2: DtypeWarning: Columns (5,65,131) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  CSAT = pd.read_csv(\"raw_data\\CSAT.csv\")\n",
      "C:\\Users\\vinotsek\\AppData\\Local\\Temp\\ipykernel_51408\\3379410815.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  ST_AOV[\"with_or_without_EC\"].fillna(\"without_EC\",inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# AOV = pd.read_excel(\"raw_data/CX AOV.xlsx\")\n",
    "CSAT = pd.read_csv(\"raw_data\\CSAT.csv\")\n",
    "CSAT=CSAT[CSAT[\"C_FISCALYR\"].isin([\"FY2024\",\"FY2023\"])]\n",
    "ST_AOV = AOV[AOV[\"CX Product Portfolio\"]==\"Success Tracks\"].groupby(\"CAV End Customer BU ID\")[\"AOV\"].sum().sort_values(ascending=False).reset_index()\n",
    "ST_AOV = ST_AOV[ST_AOV[\"AOV\"]>=10000]\n",
    "AOV1 = AOV[AOV[\"CAV End Customer BU ID\"].isin(ST_AOV[\"CAV End Customer BU ID\"])]\n",
    "EC_AOV = AOV1[AOV1[\"CX Product Category\"]==\"Expert Care Svcs\"].groupby(\"CAV End Customer BU ID\")[\"AOV\"].sum().reset_index()\n",
    "EC_AOV = EC_AOV[EC_AOV[\"AOV\"]>=10000]\n",
    "EC_AOV[\"with_or_without_EC\"] = \"with_EC\"\n",
    "ST_AOV[\"with_or_without_EC\"]=ST_AOV[\"CAV End Customer BU ID\"].map(dict(zip(EC_AOV[\"CAV End Customer BU ID\"],EC_AOV[\"with_or_without_EC\"])))\n",
    "ST_AOV[\"with_or_without_EC\"].fillna(\"without_EC\",inplace=True)\n",
    "CSAT=CSAT[CSAT[\"E_CAVCUSTOMERBUID\"].isin(ST_AOV[\"CAV End Customer BU ID\"])]\n",
    "mapping_dict = dict(zip(ST_AOV[\"CAV End Customer BU ID\"], ST_AOV[\"with_or_without_EC\"]))\n",
    "CSAT[\"with_or_without_EC\"] = CSAT[\"E_CAVCUSTOMERBUID\"].map(mapping_dict)\n",
    "CSAT.to_excel(\"CSAT_Output.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7370a4-73bf-4d31-bbf2-42eb724250f7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# New Logo (Identify the new customers for a given offer within the complementary offer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0feef07-a408-4d1e-992f-0f44d1f4d4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vinotsek\\AppData\\Local\\Temp\\ipykernel_27088\\2831805099.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ST[\"CAV End Customer BU ID\"]=ST[\"CAV End Customer BU ID\"].astype(\"str\")\n",
      "C:\\Users\\vinotsek\\AppData\\Local\\Temp\\ipykernel_27088\\2831805099.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ST[\"CustSL2\"] = ST[\"CAV End Customer BU ID\"]+\"*\"+ST[\"Sales Level 2\"]\n",
      "C:\\Users\\vinotsek\\AppData\\Local\\Temp\\ipykernel_27088\\2831805099.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  EC[\"CAV End Customer BU ID\"]=EC[\"CAV End Customer BU ID\"].astype(\"str\")\n",
      "C:\\Users\\vinotsek\\AppData\\Local\\Temp\\ipykernel_27088\\2831805099.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  EC[\"CustSL2\"] = EC[\"CAV End Customer BU ID\"]+\"*\"+EC[\"Sales Level 2\"]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$207.93M\n",
      "620\n"
     ]
    }
   ],
   "source": [
    "# New Logo for EC \n",
    "ST = CX_[CX_[\"CX Product Portfolio\"]==\"Success Tracks\"]\n",
    "ST1 = ST.groupby([\"CAV End Customer BU ID\",\"Sales Level 2\"])[\"AOV\"].sum().sort_values(ascending = False).reset_index()\n",
    "ST1= ST1[ST1[\"AOV\"]>=161000]\n",
    "ST1[\"CAV End Customer BU ID\"]=ST1[\"CAV End Customer BU ID\"].astype(\"str\")\n",
    "ST1[\"CustSL2\"]=ST1[\"CAV End Customer BU ID\"]+\"*\" +ST1[\"Sales Level 2\"]\n",
    "ST1=ST1.iloc[:,3]\n",
    "EC = CX_[CX_[\"CX Product Category\"]==\"Expert Care Svcs\"]\n",
    "EC1 = EC.groupby([\"CAV End Customer BU ID\",\"Sales Level 2\"])[\"AOV\"].sum().sort_values(ascending = False).reset_index()\n",
    "EC1= EC1[EC1[\"AOV\"]>=50000]\n",
    "EC1[\"CAV End Customer BU ID\"]=EC1[\"CAV End Customer BU ID\"].astype(\"str\")\n",
    "EC1[\"CustSL2\"]=EC1[\"CAV End Customer BU ID\"]+\"*\" +EC1[\"Sales Level 2\"]\n",
    "EC1=EC1.iloc[:,3]\n",
    "ST2=pd.DataFrame(ST1[~ST1.isin(EC1)])\n",
    "\n",
    "#Old Logo of EC for SL2 Avg AOV Mapping\n",
    "ST[\"CAV End Customer BU ID\"]=ST[\"CAV End Customer BU ID\"].astype(\"str\")\n",
    "ST[\"CustSL2\"] = ST[\"CAV End Customer BU ID\"]+\"*\"+ST[\"Sales Level 2\"]\n",
    "ST3 = ST[ST[\"CustSL2\"].isin(ST1)]\n",
    "ST3 = ST3[ST3[\"CustSL2\"].isin(EC1)]\n",
    "ST3 = ST3[[\"CustSL2\"]]\n",
    "EC[\"CAV End Customer BU ID\"]=EC[\"CAV End Customer BU ID\"].astype(\"str\")\n",
    "EC[\"CustSL2\"] = EC[\"CAV End Customer BU ID\"]+\"*\"+EC[\"Sales Level 2\"]\n",
    "EC2= EC[EC[\"CustSL2\"].isin(ST3[\"CustSL2\"])]\n",
    "EC2=EC2.groupby([\"CAV End Customer BU ID\",\"Sales Level 2\"])[\"AOV\"].sum().sort_values(ascending = False).reset_index()\n",
    "EC2 = EC2.groupby([\"Sales Level 2\"])[\"AOV\"].mean().sort_values(ascending = False).reset_index()\n",
    "EC2 = dict(zip(EC2[\"Sales Level 2\"],EC2[\"AOV\"]))\n",
    "\n",
    "#Mapping (Tier, CAV BU Name, L2 Oppty)\n",
    "ST2[['CAV End Customer BU ID', 'Sales Level 2']] = ST2['CustSL2'].str.split('*', expand=True)\n",
    "ST2[\"New_Logo_Oppty\"]=ST2[\"Sales Level 2\"].map(EC2)\n",
    "map=CX_[[\"CAV End Customer BU ID\",\"Tier\"]].drop_duplicates()\n",
    "map[\"CAV End Customer BU ID\"] = map[\"CAV End Customer BU ID\"].astype(\"str\")\n",
    "ST2[\"Tier\"] = ST2[\"CAV End Customer BU ID\"].map(dict(zip(map[\"CAV End Customer BU ID\"],map[\"Tier\"])))\n",
    "map1=CX_[[\"CAV End Customer BU ID\",\"CAV End Customer BU Name\"]].drop_duplicates()\n",
    "map1[\"CAV End Customer BU ID\"] = map1[\"CAV End Customer BU ID\"].astype(\"str\")\n",
    "ST2[\"CAV End Customer BU Name\"] = ST2[\"CAV End Customer BU ID\"].map(dict(zip(map1[\"CAV End Customer BU ID\"],map1[\"CAV End Customer BU Name\"])))\n",
    "x=ST2[\"New_Logo_Oppty\"].sum()\n",
    "print(\"${:,.2f}M\".format(x / 1_000000))\n",
    "print(ST2.shape[0])\n",
    "ST2.to_excel(\"EC_New_Logo.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472bf4ef-79a0-419e-83df-9d31b31054f6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Printing Commentary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "9bc822a2-a247-4f99-8baf-508a15e7cab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redirect stdout to a StringIO object\n",
    "stdout_backup = sys.stdout\n",
    "sys.stdout = StringIO()\n",
    "\n",
    "# Your print statements\n",
    "print(f\"${round(CX['CA Service Bookings Net'].sum()/1e6)}M in ST Bookings (Total) from {CX['ERP Deal ID'].nunique()} ST Deals in last two years.\")\n",
    "print(f\"${round(CX[CX['EC_Deal']=='Y']['CA Service Bookings Net'].sum()/1e6)}M in ST Bookings (Total) from {CX[CX['EC_Deal']=='Y']['ERP Deal ID'].nunique()} ST Deals with EC in last two years.\")\n",
    "print(\"With t-statistic of 7.61 and p value of <0.05, two-sample t-test rejects the null hypothesis that average discounts between ST Deals with EC and ST Deals without EC are equal, at a 95% confidence level\")\n",
    "print(\"Statistically, the average discount difference between ST deals with EC and those without ranges from 7.9 to 13.4 percentage points, at a 95% confidence level\")\n",
    "#Discounted calculated at aggregated level not average at deal level\n",
    "print(\"The potential savings from selling ST deals with EC at the same discount rate as ST deals without EC amount to $\",round(CX[CX[\"EC_Deal\"]==\"Y\"][\"CA Service Bookings Standard List\"].sum()*(0.685-0.628)/1e6,0),\"M over the last two years.\")\n",
    "\n",
    "# Get the output as a string\n",
    "output_string = sys.stdout.getvalue()\n",
    "\n",
    "# Split the output string into a list based on newline character\n",
    "output_list = output_string.strip().split('\\n')\n",
    "\n",
    "# Restore stdout\n",
    "sys.stdout = stdout_backup\n",
    "\n",
    "output_df = pd.DataFrame(output_list, columns=['Commentary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e147f1-4f6f-44ec-86e4-e825d4135631",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Writing to output to excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "66aec3ad-4dd9-44e2-b6b2-d1cdd2d4c2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter('latest.xlsx') as writer:\n",
    "    CX1.to_excel(writer, sheet_name='ST_Bookings',index=False)\n",
    "    CX2.to_excel(writer, sheet_name='EC_Bookings',index=False)\n",
    "    CX.to_excel(writer,sheet_name='raw_data',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
